<html>
<head>
<title>KG-BIAS Workshop 2020</title>
</head>
<body>
<h1>KG-BIAS Workshop 2020</h1>

Editors:<br />
Edgar Meij (Bloomberg)<br />
Tara Safavi (Uni of Michigan)<br />
Chenyan Xiong (Microsoft Research)<br />
Gianluca Demartini (Uni of Queensland)<br />
Miriam Redi (Wikimedia Foundation)<br />
Fatma &#214;zcan (IBM Research)<br /><br />
Virtual event, June 25, 2020<br />

The KG-BIAS 2020 workshop touches on biases and how they surface in knowledge graphs (KGs), biases in the source data that is used to create KGs, methods for measuring or remediating bias in KGs, but also identifying other biases such as how and which languages are represented in automatically constructed KGs or how personal KGs might incur inherent biases. The goal of this workshop is to uncover how various types of biases are introduced into KGs, investigate how to measure, and propose methods to remediate them.<br /><br />
  
<dl>
<dt><b>Introduction to the KG-BIAS Workshop at AKBC 2020</b></dt>
<dd>Edgar Meij, Tara Safavi, Chenyan Xiong, Gianluca Demartini, Miriam Redi, Fatma &#214;zcan<br />
(paper 
REPORT-NO:KGBias/2020/01
)
</dd>
</dl>

<dl>
<dt><b>From Knowledge Graphs to Knowledge Practices: On the Need for Transparency and Explainability in Enterprise Knowledge Graph Applications.</b></dt>
<dd>Christine Wolf<br />
(paper 
REPORT-NO:KGBias/2020/02
)
</dd>
</dl>

<dl>
<dt><b>Assessing Demographic Bias in Named Entity Recognition.</b></dt>
<dd>Shubhanshu Mishra, Sijun He, Luca Belli<br />
(paper 
REPORT-NO:KGBias/2020/03
)
</dd>
</dl>

<dl>
<dt><b>Bias in Conversational Search: The Double-Edged Sword of the Personalized Knowledge Graph</b></dt>
<dd>Emma Gerritse, Faegheh Hasibi, Arjen P. de Vries<br />
(paper 
REPORT-NO:KGBias/2020/04
)
</dd>
</dl>

<dl>
<dt><b>Measuring social bias in knowledge graph embeddings</b></dt>
<dd>Joseph Fisher, Dave Palfrey, Arpit Mittal, Christos Christodoulopoulos<br />
(paper 
REPORT-NO:KGBias/2020/05
)
</dd>
</dl>

</body>
</html>


